{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93faa01d-ce47-4723-989c-f12ee79642ac",
   "metadata": {},
   "source": [
    "## Compare the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c8eba3-7a20-4e6d-93b6-79a0fba7aca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmimo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmimo_unet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MimoUnetModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmimo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msen12tp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msen12tp_datamodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_datamodule\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming the model configuration is already set, just like in the training script\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define the arguments or use a config dictionary\u001b[39;00m\n",
      "File \u001b[0;32m~/MIMO-Unet-cov/mimo/models/mimo_unet.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArgumentParser\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal, Dict, Tuple, Any\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmimo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UncertaintyLoss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightning'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from mimo.models.mimo_unet import MimoUnetModel\n",
    "from mimo.tasks.sen12tp.sen12tp_datamodule import get_datamodule\n",
    "\n",
    "# Assuming the model configuration is already set, just like in the training script\n",
    "\n",
    "# Define the arguments or use a config dictionary\n",
    "args = {\n",
    "    'seed': 42,\n",
    "    'checkpoint_path': 'MIMO_NDVI_Prediction_Gauss/1yt2l40t/checkpoints/last.ckpt',  # Provide the path to your checkpoint\n",
    "    'num_loss_function_params': 2,\n",
    "    'num_subnetworks': 2,\n",
    "    'filter_base_count': 64,\n",
    "    'center_dropout_rate': 0.1,\n",
    "    'final_dropout_rate': 0.1,\n",
    "    'encoder_dropout_rate': 0.1,\n",
    "    'core_dropout_rate': 0.1,\n",
    "    'decoder_dropout_rate': 0.1,\n",
    "    'loss_buffer_size': 1024,\n",
    "    'loss_buffer_temperature': 0.5,\n",
    "    'input_repetition_probability': 0.0,\n",
    "    'batch_repetitions': 1,\n",
    "    'loss': 'mse',  # Adjust based on your actual loss function\n",
    "    'weight_decay': 0.0001,\n",
    "    'learning_rate': 0.0001,\n",
    "}\n",
    "\n",
    "# Initialize the datamodule (this can be modified based on your setup)\n",
    "dm = get_datamodule(args)\n",
    "\n",
    "# Instantiate the model (ensure to use the same parameters as during training)\n",
    "model = MimoUnetModel(\n",
    "    in_channels=len(dm.model_inputs),\n",
    "    out_channels=len(dm.model_targets) * args['num_loss_function_params'],\n",
    "    num_subnetworks=args['num_subnetworks'],\n",
    "    filter_base_count=args['filter_base_count'],\n",
    "    center_dropout_rate=args['center_dropout_rate'],\n",
    "    final_dropout_rate=args['final_dropout_rate'],\n",
    "    encoder_dropout_rate=args['encoder_dropout_rate'],\n",
    "    core_dropout_rate=args['core_dropout_rate'],\n",
    "    decoder_dropout_rate=args['decoder_dropout_rate'],\n",
    "    loss_buffer_size=args['loss_buffer_size'],\n",
    "    loss_buffer_temperature=args['loss_buffer_temperature'],\n",
    "    input_repetition_probability=args['input_repetition_probability'],\n",
    "    batch_repetitions=args['batch_repetitions'],\n",
    "    loss=args['loss'],\n",
    "    weight_decay=args['weight_decay'],\n",
    "    learning_rate=args['learning_rate'],\n",
    "    seed=args['seed'],\n",
    ")\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(args['checkpoint_path'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Now we can use the model to make predictions\n",
    "test_data = dm.test_dataloader()  # Ensure the dataloader is set up for your test dataset\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_data:\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs)\n",
    "\n",
    "# Optionally save the predictions (or process them further)\n",
    "for i, pred in enumerate(predictions):\n",
    "    save_image(pred, f'prediction_{i}.png')  # Replace with actual saving function if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4e9cf-50bf-4c2f-b15a-0c42b66dd23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa0f4a-ac45-4fff-aaa6-4e666bc5a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimo.models.mimo_unet import MimoUnetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713e71-3d72-4e88-9fc6-a96dda30f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your model is defined as `model` and the checkpoint is saved as 'checkpoint.pth'\n",
    "checkpoint_path = 'MIMO_NDVI_Prediction_Gauss/1yt2l40t/checkpoints/last.ckpt'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Assuming the checkpoint contains 'model_state_dict' for the model weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
