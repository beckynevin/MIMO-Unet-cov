{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93faa01d-ce47-4723-989c-f12ee79642ac",
   "metadata": {},
   "source": [
    "## Compare the trained models\n",
    "Load the checkpoints, get the test datamodel up and running, access the two channel output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371111f0-fde9-4d84-97e1-f3f5e394074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mimo.models.mimo_unet import MimoUnetModel\n",
    "from mimo.tasks.sen12tp.sen12tp_datamodule import get_datamodule\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a41eb0-880e-4a79-8a83-96406582eaf3",
   "metadata": {},
   "source": [
    "### First, load up the Gaussian model ('MIMO_NDVI_Prediction_Gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8eba3-7a20-4e6d-93b6-79a0fba7aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'seed': 1,\n",
    "    'checkpoint_path': 'MIMO_NDVI_Prediction_Gauss/1yt2l40t/checkpoints/last.ckpt',\n",
    "    'dataset_dir': '/deepskieslab/rnevin/zenodo_data',\n",
    "    'batch_size': 32,\n",
    "    'num_loss_function_params': 2,\n",
    "    'num_subnetworks': 2,\n",
    "    'filter_base_count': 30,\n",
    "    'center_dropout_rate': 0.1,\n",
    "    'final_dropout_rate': 0.1,\n",
    "    'encoder_dropout_rate': 0.0,\n",
    "    'core_dropout_rate': 0.0,\n",
    "    'decoder_dropout_rate': 0.0,\n",
    "    'loss_buffer_size': 10,\n",
    "    'loss_buffer_temperature': 0.3,\n",
    "    'input_repetition_probability': 0.0,\n",
    "    'batch_repetitions': 1,\n",
    "    'patch_size': 256,\n",
    "    'stride': 249,\n",
    "    'loss': 'gaussian_nll',  # Adjust based on your actual loss function\n",
    "    'weight_decay': 0.0001,\n",
    "    'learning_rate': 0.0001,\n",
    "    'num_workers': 30,\n",
    "    'training_set_percentage': 1.0,\n",
    "}\n",
    "\n",
    "args[\"input\"] = [\"VV_sigma0\", \"VH_sigma0\"]\n",
    "args[\"target\"] = [\"NDVI\"]  # Example target\n",
    "\n",
    "'''\n",
    "python scripts/train/train_ndvi.py   --max_epochs 40   --batch_size 32   -t NDVI   -i VV_sigma0   -i VH_sigma0   --project \"MIMO_NDVI_Prediction_Gauss\"\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "args = Namespace(**args)  # Convert dictionary to Namespace\n",
    "dm_gauss = get_datamodule(args)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model (ensure to use the same parameters as during training)\n",
    "model_gauss = MimoUnetModel(\n",
    "    in_channels=len(dm_gauss.model_inputs),\n",
    "    out_channels=len(dm_gauss.model_targets) * args.num_loss_function_params,\n",
    "    num_subnetworks=args.num_subnetworks,\n",
    "    filter_base_count=args.filter_base_count,\n",
    "    center_dropout_rate=args.center_dropout_rate,\n",
    "    final_dropout_rate=args.final_dropout_rate,\n",
    "    encoder_dropout_rate=args.encoder_dropout_rate,\n",
    "    core_dropout_rate=args.core_dropout_rate,\n",
    "    decoder_dropout_rate=args.decoder_dropout_rate,\n",
    "    loss_buffer_size=args.loss_buffer_size,\n",
    "    loss_buffer_temperature=args.loss_buffer_temperature,\n",
    "    input_repetition_probability=args.input_repetition_probability,\n",
    "    batch_repetitions=args.batch_repetitions,\n",
    "    loss=args.loss,\n",
    "    weight_decay=args.weight_decay,\n",
    "    learning_rate=args.learning_rate,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "# this is a necessary step because it adds extra prefix from the wrapper\n",
    "model_gauss.compile()\n",
    "\n",
    "#print(args)\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(args.checkpoint_path, map_location=torch.device('cpu'))\n",
    "#print(checkpoint.keys())\n",
    "model_gauss.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_gauss.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cd819-c9e0-4bd9-a2c2-f48fb7eb897d",
   "metadata": {},
   "source": [
    "## Now load the Laplace one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966b105-f728-4f36-87f2-11723da8814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'seed': 1,\n",
    "    'checkpoint_path': 'MIMO NDVI Prediction/hhid6a04/checkpoints/last.ckpt',\n",
    "    'dataset_dir': '/deepskieslab/rnevin/zenodo_data',\n",
    "    'batch_size': 32,\n",
    "    'num_loss_function_params': 2,\n",
    "    'num_subnetworks': 2,\n",
    "    'filter_base_count': 30,\n",
    "    'center_dropout_rate': 0.1,\n",
    "    'final_dropout_rate': 0.1,\n",
    "    'encoder_dropout_rate': 0.0,\n",
    "    'core_dropout_rate': 0.0,\n",
    "    'decoder_dropout_rate': 0.0,\n",
    "    'loss_buffer_size': 10,\n",
    "    'loss_buffer_temperature': 0.3,\n",
    "    'input_repetition_probability': 0.0,\n",
    "    'batch_repetitions': 1,\n",
    "    'patch_size': 256,\n",
    "    'stride': 249,\n",
    "    'loss': 'laplace_nll',  # Adjust based on your actual loss function\n",
    "    'weight_decay': 0.0001,\n",
    "    'learning_rate': 0.0001,\n",
    "    'num_workers': 30,\n",
    "    'training_set_percentage': 1.0,\n",
    "}\n",
    "\n",
    "args[\"input\"] = [\"VV_sigma0\", \"VH_sigma0\"]\n",
    "args[\"target\"] = [\"NDVI\"]  # Example target\n",
    "\n",
    "'''\n",
    "python scripts/train/train_ndvi.py   --max_epochs 40   --batch_size 32   -t NDVI   -i VV_sigma0   -i VH_sigma0   --project \"MIMO_NDVI_Prediction_Gauss\"\n",
    "'''\n",
    "\n",
    "args = Namespace(**args)  # Convert dictionary to Namespace\n",
    "dm_laplace = get_datamodule(args)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model (ensure to use the same parameters as during training)\n",
    "model_laplace = MimoUnetModel(\n",
    "    in_channels=len(dm_laplace.model_inputs),\n",
    "    out_channels=len(dm_laplace.model_targets) * args.num_loss_function_params,\n",
    "    num_subnetworks=args.num_subnetworks,\n",
    "    filter_base_count=args.filter_base_count,\n",
    "    center_dropout_rate=args.center_dropout_rate,\n",
    "    final_dropout_rate=args.final_dropout_rate,\n",
    "    encoder_dropout_rate=args.encoder_dropout_rate,\n",
    "    core_dropout_rate=args.core_dropout_rate,\n",
    "    decoder_dropout_rate=args.decoder_dropout_rate,\n",
    "    loss_buffer_size=args.loss_buffer_size,\n",
    "    loss_buffer_temperature=args.loss_buffer_temperature,\n",
    "    input_repetition_probability=args.input_repetition_probability,\n",
    "    batch_repetitions=args.batch_repetitions,\n",
    "    loss=args.loss,\n",
    "    weight_decay=args.weight_decay,\n",
    "    learning_rate=args.learning_rate,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "# this is a necessary step because it adds extra prefix from the wrapper\n",
    "model_laplace.compile()\n",
    "\n",
    "print(args)\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(args.checkpoint_path, map_location=torch.device('cpu'))\n",
    "print(checkpoint.keys())\n",
    "model_laplace.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_laplace.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9396a56-f1bc-4a98-9fa8-cf855ed57c0b",
   "metadata": {},
   "source": [
    "I need to compare the two datamodels and make sure they're the same. I think they should be ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7bbe2-5f9f-49ad-955b-7e634f2c7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the model to make predictions\n",
    "test_data_gauss = dm_gauss.train_dataloader()  # Ensure the dataloader is set up for your test dataset\n",
    "test_data_laplace = dm_laplace.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73c10e-37bc-447b-89b9-dcb426da98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = True\n",
    "counter = 0\n",
    "# Make predictions\n",
    "predictions_gauss = []\n",
    "labels_gauss = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_data_gauss:\n",
    "        image_tensor = inputs[\"image\"]  # Extract the tensor\n",
    "        label_tensor = inputs[\"label\"]\n",
    "        \n",
    "\n",
    "        image_tensor = image_tensor.unsqueeze(1) # adding subnetwork channel\n",
    "        # (B, S, C, H, W) = x.shape\n",
    "        # batch, # subnetworks, channels, height, width\n",
    "        \n",
    "        # now duplicate, this saves on memory\n",
    "        image_tensor = image_tensor.expand(-1, 2, -1, -1, -1)\n",
    "        # this is the option that creates actual copies\n",
    "        # image_tensor = image_tensor.repeat(1, 2, 1, 1, 1)\n",
    "        \n",
    "        if plot:\n",
    "            print(np.shape(image_tensor))\n",
    "            fig = plt.figure()\n",
    "            ax0 = fig.add_subplot(221)\n",
    "            im0 = ax0.imshow(image_tensor[1,0,0,:,:])\n",
    "            plt.colorbar(im0)\n",
    "            ax0.set_title('input')\n",
    "    \n",
    "            ax1 = fig.add_subplot(222)\n",
    "            im1 = ax1.imshow(label_tensor[0,0,:,:])\n",
    "            plt.colorbar(im1)\n",
    "            ax1.set_title('label')\n",
    "        \n",
    "        outputs = model_gauss(image_tensor)  # Pass only the tensor to the model\n",
    "        \n",
    "        if plot:\n",
    "            print(np.shape(outputs))\n",
    "            print(type(outputs))\n",
    "    \n",
    "            output_mean = outputs[0]\n",
    "            output_f2 = outputs[1]\n",
    "            \n",
    "            mean = output_mean[0, 0, 0, :, :].cpu().detach().numpy()\n",
    "            f2 = output_f2[0, 0, 0, :, :].cpu().detach().numpy()\n",
    "    \n",
    "            ax2 = fig.add_subplot(223)\n",
    "            im2 = ax2.imshow(mean)\n",
    "            plt.colorbar(im2)\n",
    "            ax2.set_title('output mean')\n",
    "    \n",
    "            ax3 = fig.add_subplot(224)\n",
    "            im3 = ax3.imshow(np.exp(f2))\n",
    "            plt.colorbar(im3)\n",
    "            ax3.set_title('output var')\n",
    "            plt.show()\n",
    "\n",
    "        # make an image for if this is well calibrated\n",
    "        \n",
    "        labels_gauss.append(label_tensor)\n",
    "        predictions_gauss.append(outputs)\n",
    "        counter+=1\n",
    "        if counter > 5:\n",
    "            STOP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffc09e-914f-4f1f-9ac6-dd61a37b6540",
   "metadata": {},
   "source": [
    "### Second, load up the Laplacian model ('MIMO NDVI Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c622345-fa1a-4dd9-aa73-b1be72c15e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_laplace = []\n",
    "labels_laplace = []\n",
    "counter = 0\n",
    "with torch.no_grad():\n",
    "    for inputs in test_data_laplace:\n",
    "        image_tensor = inputs[\"image\"]  # Extract the tensor\n",
    "        label_tensor = inputs[\"label\"]\n",
    "\n",
    "        image_tensor = image_tensor.unsqueeze(1) # adding subnetwork channel\n",
    "        # (B, S, C, H, W) = x.shape\n",
    "        # batch, # subnetworks, channels, height, width\n",
    "        \n",
    "        # now duplicate, this saves on memory\n",
    "        image_tensor = image_tensor.expand(-1, 2, -1, -1, -1)\n",
    "        # this is the option that creates actual copies\n",
    "        # image_tensor = image_tensor.repeat(1, 2, 1, 1, 1)\n",
    "        if plot:\n",
    "            print(np.shape(image_tensor))\n",
    "            fig = plt.figure()\n",
    "            ax0 = fig.add_subplot(221)\n",
    "            im0 = ax0.imshow(image_tensor[1,0,0,:,:])\n",
    "            plt.colorbar(im0)\n",
    "            ax0.set_title('input')\n",
    "    \n",
    "            ax1 = fig.add_subplot(222)\n",
    "            im1 = ax1.imshow(label_tensor[0,0,:,:])\n",
    "            plt.colorbar(im1)\n",
    "            ax1.set_title('label')\n",
    "        \n",
    "        \n",
    "        outputs = model_laplace(image_tensor)  # Pass only the tensor to the model\n",
    "        if plot:\n",
    "            print(np.shape(outputs))\n",
    "            print(type(outputs))\n",
    "    \n",
    "            output_mean = outputs[0]\n",
    "            output_f2 = outputs[1]\n",
    "            \n",
    "            mean = output_mean[0, 0, 0, :, :].cpu().detach().numpy()\n",
    "            f2 = output_f2[0, 0, 0, :, :].cpu().detach().numpy()\n",
    "    \n",
    "            ax2 = fig.add_subplot(223)\n",
    "            im2 = ax2.imshow(mean)\n",
    "            plt.colorbar(im2)\n",
    "            ax2.set_title('output mean')\n",
    "    \n",
    "            ax3 = fig.add_subplot(224)\n",
    "            im3 = ax3.imshow(np.exp(f2))\n",
    "            plt.colorbar(im3)\n",
    "            ax3.set_title('output b')\n",
    "            plt.show()\n",
    "\n",
    "        labels_laplace.append(label_tensor)\n",
    "        predictions_laplace.append(outputs)\n",
    "        counter+=1\n",
    "        if counter > 5:\n",
    "            STOP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea037c-f82d-4679-87c7-0ca2927b8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(labels_laplace), np.shape(predictions_laplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a114d-5ea3-412d-ac5b-27705e5e788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "true_gauss = labels_gauss[n][0,0,:,:]\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(231)\n",
    "im0 = ax0.imshow(true_gauss)\n",
    "plt.colorbar(im0, fraction=0.046)\n",
    "ax0.set_title('Label')\n",
    "\n",
    "mean_gauss = predictions_gauss[n][0][0, 0, 0, :, :].cpu().detach().numpy()\n",
    "f2_gauss = predictions_gauss[n][1][0, 0, 0, :, :].cpu().detach().numpy()\n",
    "\n",
    "ax1 = fig.add_subplot(232)\n",
    "im1 = ax1.imshow(mean_gauss)\n",
    "plt.colorbar(im1, fraction=0.046)\n",
    "ax1.set_title(r'Mean prediction, $\\mu$')\n",
    "\n",
    "ax2 = fig.add_subplot(233)\n",
    "im2 = ax2.imshow(np.exp(f2_gauss)**(0.5))\n",
    "plt.colorbar(im2, fraction=0.046)\n",
    "ax2.set_title(r'Std prediction, $\\sigma$')\n",
    "\n",
    "# the question 'is it calibrated'\n",
    "\n",
    "ax3 = fig.add_subplot(234)\n",
    "im3 = ax3.imshow(abs((mean_gauss - true_gauss.detach().numpy())/(np.exp(f2_gauss)**(0.5))))\n",
    "plt.colorbar(im3, fraction=0.046)\n",
    "ax3.set_title(r'($\\mu$ - true)/ $\\sigma$')\n",
    "\n",
    "# Calculate Z-score image\n",
    "z_img = np.abs((mean_gauss - true_gauss.detach().numpy()) / (np.exp(f2_gauss)**(0.5)))\n",
    "\n",
    "# Create outlier mask (pixels where z > 4)\n",
    "outlier_mask = z_img > 3\n",
    "\n",
    "# Create RGB image to highlight outliers in red\n",
    "outlier_rgb = np.zeros((*z_img.shape, 3))\n",
    "outlier_rgb[outlier_mask] = [1, 0, 0]  # red\n",
    "\n",
    "# Plot it in ax4\n",
    "ax4 = fig.add_subplot(235)\n",
    "im4 = ax4.imshow(outlier_rgb)\n",
    "ax4.set_title(\"3σ Outliers (red)\")\n",
    "\n",
    "# Calculate percentage of outlier pixels\n",
    "percent_outliers = 100 * np.sum(outlier_mask) / outlier_mask.size\n",
    "ax4.text(0.5, 0.1, f\"{percent_outliers:.2f}% OODR\",\n",
    "         transform=ax4.transAxes, ha=\"center\", fontsize=8, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"OODR_gauss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8c92b-2915-47ce-8813-dc19dcfe8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_laplace = labels_laplace[n][0,0,:,:]\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(231)\n",
    "im0 = ax0.imshow(true_laplace)\n",
    "plt.colorbar(im0, fraction=0.046)\n",
    "ax0.set_title('Label')\n",
    "\n",
    "mean_laplace = predictions_laplace[n][0][0, 0, 0, :, :].cpu().detach().numpy()\n",
    "f2_laplace = predictions_laplace[n][1][0, 0, 0, :, :].cpu().detach().numpy()\n",
    "\n",
    "ax1 = fig.add_subplot(232)\n",
    "im1 = ax1.imshow(mean_laplace)\n",
    "plt.colorbar(im1, fraction=0.046)\n",
    "ax1.set_title(r'Mean prediction, $\\mu$')\n",
    "\n",
    "ax2 = fig.add_subplot(233)\n",
    "im2 = ax2.imshow(np.exp(f2_laplace))\n",
    "plt.colorbar(im2, fraction=0.046)\n",
    "ax2.set_title(r'Scale prediction, $b$')\n",
    "\n",
    "# the question 'is it calibrated'\n",
    "\n",
    "ax3 = fig.add_subplot(234)\n",
    "im3 = ax3.imshow(abs((mean_laplace - true_laplace.detach().numpy())/np.exp(f2_laplace)))\n",
    "plt.colorbar(im3, fraction=0.046)\n",
    "ax3.set_title(r'($\\mu$ - true)/ $b$')\n",
    "\n",
    "# Calculate Z-score image\n",
    "z_img = np.abs((mean_laplace - true_laplace.detach().numpy()) / np.exp(f2_laplace))\n",
    "\n",
    "# Create outlier mask (pixels where z > 4)\n",
    "outlier_mask = z_img > 3\n",
    "\n",
    "# Create RGB image to highlight outliers in red\n",
    "outlier_rgb = np.zeros((*z_img.shape, 3))\n",
    "outlier_rgb[outlier_mask] = [1, 0, 0]  # red\n",
    "\n",
    "# Plot it in ax4\n",
    "ax4 = fig.add_subplot(235)\n",
    "im4 = ax4.imshow(outlier_rgb)\n",
    "ax4.set_title(\"3σ Outliers (red)\")\n",
    "\n",
    "# Calculate percentage of outlier pixels\n",
    "percent_outliers = 100 * np.sum(outlier_mask) / outlier_mask.size\n",
    "ax4.text(0.5, 0.1, f\"{percent_outliers:.2f}% OODR\",\n",
    "         transform=ax4.transAxes, ha=\"center\", fontsize=8, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"OODR_laplace.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32629b0-05fc-44c4-8203-e055aebcc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pixelwise_ece(\n",
    "    y_true, y_pred, y_uncertainty, num_bins=10, error_type=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Compute Expected Calibration Error (ECE) for pixel-wise uncertainty calibration.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: np.ndarray, ground truth values (H, W)\n",
    "    - y_pred: np.ndarray, predicted values (H, W)\n",
    "    - y_uncertainty: np.ndarray, predicted uncertainties (H, W)\n",
    "    - num_bins: int, number of bins for uncertainty calibration\n",
    "    - error_type: str, \"absolute\" for MAE, \"squared\" for MSE\n",
    "    \n",
    "    Returns:\n",
    "    - ece: float, the expected calibration error\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten arrays to handle pixel-wise values\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_uncertainty = y_uncertainty.flatten()\n",
    "\n",
    "    # Compute empirical error\n",
    "    if error_type == \"absolute\":\n",
    "        empirical_error = np.abs(y_pred - y_true)\n",
    "    elif error_type == \"squared\":\n",
    "        empirical_error = (y_pred - y_true) ** 2\n",
    "    else:\n",
    "        raise ValueError(\"error_type must be 'absolute' or 'squared'.\")\n",
    "\n",
    "    # Define bin edges for uncertainty\n",
    "    bin_edges = np.linspace(y_uncertainty.min(), y_uncertainty.max(), num_bins + 1)\n",
    "    \n",
    "    # Initialize ECE\n",
    "    ece = 0.0\n",
    "    ece_bin = []\n",
    "    total_pixels = len(y_true)\n",
    "\n",
    "    # Compute ECE over bins\n",
    "    for i in range(num_bins):\n",
    "        bin_mask = (y_uncertainty >= bin_edges[i]) & (y_uncertainty < bin_edges[i + 1])\n",
    "        bin_size = np.sum(bin_mask)\n",
    "        \n",
    "        if bin_size > 0:\n",
    "            avg_pred_uncertainty = np.mean(y_uncertainty[bin_mask])\n",
    "            avg_empirical_error = np.mean(empirical_error[bin_mask])\n",
    "\n",
    "            ece += (bin_size / total_pixels) * np.abs(avg_pred_uncertainty - avg_empirical_error)\n",
    "            ece_bin.append((bin_size / total_pixels) * np.abs(avg_pred_uncertainty - avg_empirical_error))\n",
    "    return ece, bin_edges, ece_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70b37d-6f11-4398-96a9-8f5a1a3cae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = true_gauss.detach().numpy()\n",
    "y_pred = mean_gauss\n",
    "y_uncertainty = np.exp(f2_gauss)**(0.5)\n",
    "\n",
    "ece_value, bin_edges, ece_bin = compute_pixelwise_ece(y_true, y_pred, y_uncertainty, num_bins=15, error_type=\"absolute\")\n",
    "print(f\"Pixel-wise ECE: {ece_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f3deb-7db7-4b44-b780-d234beb912c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bin centers for better visualization\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Midpoints of bins\n",
    "\n",
    "# Create histogram using bar plot\n",
    "plt.bar(bin_centers, ece_bin, width=np.diff(bin_edges), align=\"center\", edgecolor=\"black\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Predicted Uncertainty\")\n",
    "plt.ylabel(\"ECE Contribution per Bin\")\n",
    "plt.title(\"ECE Contribution Histogram\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f07ac-59ce-431d-99f9-0b6f70cca34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Create figure and main axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Main bar plot\n",
    "ax.bar(bin_centers, ece_bin, width=np.diff(bin_edges), align=\"center\", edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Predicted Uncertainty\")\n",
    "ax.set_ylabel(\"ECE Contribution per Bin\")\n",
    "ax.set_title(\"ECE Contribution Histogram\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# **Inset panel settings** (adjust size and position)\n",
    "inset_size = \"25%\"  # Percentage of main figure size\n",
    "inset_positions = [(0.65, 0.6), (0.15, 0.6), (0.40, 0.2)]  # (x, y) relative to figure\n",
    "\n",
    "img_min = min([np.min(y_true), np.min(y_pred)])\n",
    "img_max = max([np.max(y_true), np.max(y_pred)])\n",
    "\n",
    "# **Inset 1: True values (y_true)**\n",
    "ax_inset1 = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"upper left\",\n",
    "                        bbox_to_anchor=(0.0, 0.6, 0.3, 0.3), bbox_transform=ax.transAxes)\n",
    "ax_inset1.imshow(y_true, cmap=\"viridis\",\n",
    "                vmin=img_min,\n",
    "                vmax=img_max)\n",
    "ax_inset1.set_title(\"True Values\", fontsize=8)\n",
    "ax_inset1.axis(\"off\")\n",
    "\n",
    "# **Inset 2: Predicted values (y_pred)**\n",
    "ax_inset2 = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"upper left\",\n",
    "                        bbox_to_anchor=(0.15, 0.6, 0.3, 0.3), bbox_transform=ax.transAxes)\n",
    "ax_inset2.imshow(y_pred, cmap=\"viridis\",\n",
    "                vmin=img_min,\n",
    "                vmax=img_max)\n",
    "ax_inset2.set_title(\"Predicted Values\", fontsize=8)\n",
    "ax_inset2.axis(\"off\")\n",
    "\n",
    "# **Inset 3: Uncertainty values (y_uncertainty)**\n",
    "ax_inset3 = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"upper left\",\n",
    "                        bbox_to_anchor=(0.3, 0.6, 0.3, 0.3), bbox_transform=ax.transAxes)\n",
    "ax_inset3.imshow(y_uncertainty, cmap=\"viridis\")\n",
    "ax_inset3.set_title(\"Uncertainty\", fontsize=8)\n",
    "ax_inset3.axis(\"off\")\n",
    "plt.savefig(\"ECE_gauss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab3e82-8d74-4544-8677-58ae37bc7c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mimo]",
   "language": "python",
   "name": "conda-env-.conda-mimo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
